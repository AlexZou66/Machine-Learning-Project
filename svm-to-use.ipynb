{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n#df = pd.read_csv('/kaggle/input/tencentforuse/edit')\nnew_df=pd.read_csv('/kaggle/input/newclustering/newclasstering.csv')\nnew_df","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:30.535603Z","iopub.execute_input":"2022-01-28T07:30:30.536145Z","iopub.status.idle":"2022-01-28T07:30:30.612243Z","shell.execute_reply.started":"2022-01-28T07:30:30.536054Z","shell.execute_reply":"2022-01-28T07:30:30.611409Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#normalized_df=(df_new-df_new.mean())/df_new.std()\n#new_df=new_df.fillna(new_df.mean())\nnew_df[['status']]=new_df[['status']].fillna(round(new_df.mean()))\nnew_df=new_df.fillna(0)\nnormalized=pd.DataFrame()\nnormalized['status']=(new_df['status']-new_df['status'].mean())/new_df['status'].std()\nnormalized['play number']=(new_df['play number']-new_df['play number'].mean())/new_df['play number'].std()\nnormalized['score']=(new_df['score']-new_df['score'].mean())/new_df['score'].std()\n#normalized['year']=new_df['year']-2015\nnormalized['year']=(new_df['year']-new_df['year'].mean())/new_df['year'].std()\n#normalized['topic']=new_df['topic']-7\nnormalized['topic']=(new_df['topic']-new_df['topic'].mean())/new_df['topic'].std()\nnormalized['1']=(new_df['1']-new_df['1'].mean())/new_df['1'].std()\nnormalized['2']=(new_df['2']-new_df['2'].mean())/new_df['2'].std()\nnormalized['sum']=(new_df['sum']-new_df['sum'].mean())/new_df['sum'].std()\nnormalized['play cat']=new_df['play cat']\ndf_last1=normalized\ndf_last1\n#new_df","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:30.613890Z","iopub.execute_input":"2022-01-28T07:30:30.614265Z","iopub.status.idle":"2022-01-28T07:30:30.654248Z","shell.execute_reply.started":"2022-01-28T07:30:30.614207Z","shell.execute_reply":"2022-01-28T07:30:30.653552Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#from lightgbm import LGBMRegressor, LGBMClassifier\nfrom sklearn.model_selection import train_test_split\n#test=df_last1[['status','score','year', 'topic','1','2','sum']]","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:30.655261Z","iopub.execute_input":"2022-01-28T07:30:30.655457Z","iopub.status.idle":"2022-01-28T07:30:31.536693Z","shell.execute_reply.started":"2022-01-28T07:30:30.655435Z","shell.execute_reply":"2022-01-28T07:30:31.535917Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"##https://blog.csdn.net/weixin_42029733/article/details/89922575\nfrom itertools import combinations\ndef combine(temp_list,n):\n    temp_list2 = []\n    for c in combinations(temp_list, n):\n        temp_list2.append(list(c))\n    return temp_list2\ntest=['status','year', 'topic','1','2']\nend_list=[]\nfor i in range(len(test)):\n    end_list.extend(list(combine(test,i)))\ndel end_list[0]\nend_list.append(test)\n#end_list","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:31.538259Z","iopub.execute_input":"2022-01-28T07:30:31.538900Z","iopub.status.idle":"2022-01-28T07:30:31.544263Z","shell.execute_reply.started":"2022-01-28T07:30:31.538867Z","shell.execute_reply":"2022-01-28T07:30:31.543637Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm, datasets\nimport sklearn.model_selection as model_selection\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:31.545094Z","iopub.execute_input":"2022-01-28T07:30:31.545486Z","iopub.status.idle":"2022-01-28T07:30:31.683383Z","shell.execute_reply.started":"2022-01-28T07:30:31.545456Z","shell.execute_reply":"2022-01-28T07:30:31.682464Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:31.684608Z","iopub.execute_input":"2022-01-28T07:30:31.685043Z","iopub.status.idle":"2022-01-28T07:30:31.689653Z","shell.execute_reply.started":"2022-01-28T07:30:31.685002Z","shell.execute_reply":"2022-01-28T07:30:31.688570Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_ratio = 0.75\nvalidation_ratio = 0.15\ntest_ratio = 0.10\n\n# train is now 75% of the entire data set\n# the _junk suffix means that we drop that variable completely\ndataX=df_last1[test]\ndataY=df_last1[\"play cat\"]\nX_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n# test is now 10% of the initial data set\n# validation is now 15% of the initial data set\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) ","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:31.690926Z","iopub.execute_input":"2022-01-28T07:30:31.691386Z","iopub.status.idle":"2022-01-28T07:30:31.709412Z","shell.execute_reply.started":"2022-01-28T07:30:31.691346Z","shell.execute_reply":"2022-01-28T07:30:31.708689Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#gamma=[0.03,0.1,0.3,1]\n#C=[0.1,1,10,100]\nC=[0.1*i for i in range(10,51)]\ngamma=[i for i in range(4,30)]\nrecord=[]\nfor g in gamma:\n#for c in C:\n    rbf = svm.SVC(kernel='rbf', gamma=g, C=2.3).fit(X_train, y_train)\n    rbf_pred = rbf.predict(X_val)\n    accuracy = accuracy_score(y_val, rbf_pred)\n    record.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(gamma, record)\nplt.title('validation accuracy vs SVM(rbf kernel) gamma')\nplt.ylabel('Accuracy')\nplt.xlabel('Gamma')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:31.710403Z","iopub.execute_input":"2022-01-28T07:30:31.710756Z","iopub.status.idle":"2022-01-28T07:30:38.088342Z","shell.execute_reply.started":"2022-01-28T07:30:31.710717Z","shell.execute_reply":"2022-01-28T07:30:38.087586Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"result=[]\ngamma=[0.5,1.0,1.5,2.0]\nC=[1.0,1.2,1.4,1.6,1.8,2.0]\nfor s in end_list:\n    #X=X_train[s]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n    rbf = svm.SVC(kernel='rbf', gamma=12, C=2.3).fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:38.089629Z","iopub.execute_input":"2022-01-28T07:30:38.089920Z","iopub.status.idle":"2022-01-28T07:30:43.572259Z","shell.execute_reply.started":"2022-01-28T07:30:38.089882Z","shell.execute_reply":"2022-01-28T07:30:43.571596Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1', '2']\nrbf = svm.SVC(kernel='rbf', gamma=12, C=2.3).fit(X_train[s], y_train)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:43.575535Z","iopub.execute_input":"2022-01-28T07:30:43.576012Z","iopub.status.idle":"2022-01-28T07:30:43.936519Z","shell.execute_reply.started":"2022-01-28T07:30:43.575981Z","shell.execute_reply":"2022-01-28T07:30:43.935631Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"##https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02\nrbf = svm.SVC(kernel='rbf', gamma=2, C=1.8).fit(X_train, y_train)\npoly = svm.SVC(kernel='poly', degree=3, C=10).fit(X_train, y_train)\nsig = svm.SVC(kernel='sigmoid', C=10).fit(X_train, y_train)\nlinear = svm.SVC(kernel='linear', C=10).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:43.937649Z","iopub.execute_input":"2022-01-28T07:30:43.938151Z","iopub.status.idle":"2022-01-28T07:30:45.142788Z","shell.execute_reply.started":"2022-01-28T07:30:43.938108Z","shell.execute_reply":"2022-01-28T07:30:45.141949Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"poly_pred = poly.predict(X_test)\nrbf_pred = rbf.predict(X_test)\nsig_pred=sig.predict(X_test)\nlinear_pred=linear.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.144044Z","iopub.execute_input":"2022-01-28T07:30:45.144279Z","iopub.status.idle":"2022-01-28T07:30:45.197929Z","shell.execute_reply.started":"2022-01-28T07:30:45.144242Z","shell.execute_reply":"2022-01-28T07:30:45.197121Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"poly_accuracy = accuracy_score(y_test, poly_pred)\npoly_f1 = f1_score(y_test, poly_pred, average='weighted')\nprint('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\nprint('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n\nrbf_accuracy = accuracy_score(y_test, rbf_pred)\nrbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\nprint('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\nprint('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))\n\nsig_accuracy = accuracy_score(y_test, sig_pred)\nsig_f1 = f1_score(y_test, sig_pred, average='weighted')\nprint('Accuracy (Sig Kernel): ', \"%.2f\" % (sig_accuracy*100))\nprint('F1 (Sig Kernel): ', \"%.2f\" % (sig_f1*100))\n\nlinear_accuracy = accuracy_score(y_test, linear_pred)\nlinear_f1 = f1_score(y_test, linear_pred, average='weighted')\nprint('Accuracy (Linear Kernel): ', \"%.2f\" % (linear_accuracy*100))\nprint('F1 (Linear Kernel): ', \"%.2f\" % (linear_f1*100))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.199320Z","iopub.execute_input":"2022-01-28T07:30:45.199544Z","iopub.status.idle":"2022-01-28T07:30:45.216627Z","shell.execute_reply.started":"2022-01-28T07:30:45.199518Z","shell.execute_reply":"2022-01-28T07:30:45.215681Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt \naccu=[]\nn_neighbors=range(10,60)\nmatric=['euclidean','manhattan','minkowski','hamming']\n#for n in n_neighbors:\nfor m in ['uniform','distance']:\n    neigh = KNeighborsClassifier(weights=m,n_neighbors=24)\n    neigh.fit(X_train, y_train)\n    neigh_pred=neigh.predict(X_val)\n    neigh_accuracy = accuracy_score(y_val, neigh_pred)\n    print(m,neigh_accuracy)\n#import matplotlib.pyplot as plt\n#plt.plot(n_neighbors, accu)\n#plt.title('validation accuracy vs Number of neighbors(K) in KNN')\n#plt.ylabel('Accuracy')\n#plt.xlabel('Number of neighbors')\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.218039Z","iopub.execute_input":"2022-01-28T07:30:45.218259Z","iopub.status.idle":"2022-01-28T07:30:45.320882Z","shell.execute_reply.started":"2022-01-28T07:30:45.218213Z","shell.execute_reply":"2022-01-28T07:30:45.319963Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"result=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = KNeighborsClassifier(weights='distance',n_neighbors=24)\n    rbf.fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.322200Z","iopub.execute_input":"2022-01-28T07:30:45.322532Z","iopub.status.idle":"2022-01-28T07:30:45.672169Z","shell.execute_reply.started":"2022-01-28T07:30:45.322497Z","shell.execute_reply":"2022-01-28T07:30:45.671513Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1']\nrbf = KNeighborsClassifier(weights='distance',n_neighbors=24)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.673370Z","iopub.execute_input":"2022-01-28T07:30:45.673861Z","iopub.status.idle":"2022-01-28T07:30:45.695010Z","shell.execute_reply.started":"2022-01-28T07:30:45.673817Z","shell.execute_reply":"2022-01-28T07:30:45.694267Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\n#reg =RidgeClassifier()\n#reg = linear_model.Lasso(alpha=0.9)\n#reg.fit(X_train, y_train)\n#reg_pred=reg.predict(X_test)\n#print(reg_pred)\n#reg_accuracy = accuracy_score(y_test, reg_pred)\n#reg_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.695965Z","iopub.execute_input":"2022-01-28T07:30:45.696253Z","iopub.status.idle":"2022-01-28T07:30:45.699932Z","shell.execute_reply.started":"2022-01-28T07:30:45.696206Z","shell.execute_reply":"2022-01-28T07:30:45.699344Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"result=[]\nalpha=[1,10,100,1000,10000,100000,1000000]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = RidgeClassifier(190)\n    rbf.fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_test[s])\n    accuracy = accuracy_score(y_test, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.701120Z","iopub.execute_input":"2022-01-28T07:30:45.701546Z","iopub.status.idle":"2022-01-28T07:30:45.897603Z","shell.execute_reply.started":"2022-01-28T07:30:45.701515Z","shell.execute_reply":"2022-01-28T07:30:45.897008Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"s=['status', '1']\nrbf = RidgeClassifier(190)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.898733Z","iopub.execute_input":"2022-01-28T07:30:45.899448Z","iopub.status.idle":"2022-01-28T07:30:45.916256Z","shell.execute_reply.started":"2022-01-28T07:30:45.899410Z","shell.execute_reply":"2022-01-28T07:30:45.915682Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\nresult=[]\nalpha=[i for i in range(1,1000)]\nfor a in alpha:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = RidgeClassifier(alpha=a)\n    rbf.fit(X_train, y_train)\n    rbf_pred = rbf.predict(X_val)\n    accuracy = accuracy_score(y_val, rbf_pred)\n    result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(alpha, result)\nplt.title('validation accuracy vs SVM(rbf kernel) gamma')\nplt.ylabel('Accuracy')\nplt.xlabel('Gamma')\nplt.legend()\nplt.show()\n#import matplotlib.pyplot as plt\n#plt.plot(range(-5,5), result)\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:45.917203Z","iopub.execute_input":"2022-01-28T07:30:45.917799Z","iopub.status.idle":"2022-01-28T07:30:50.668975Z","shell.execute_reply.started":"2022-01-28T07:30:45.917767Z","shell.execute_reply":"2022-01-28T07:30:50.668188Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nresult=[]\nC=[0.001*i for i in range(1,15)]\nfor c in C:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = LogisticRegression(C=c,random_state=0)\n    rbf.fit(X_train, y_train)\n    rbf_pred = rbf.predict(X_test)\n    accuracy = accuracy_score(y_test, rbf_pred)\n    result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(C, result)\nplt.title('validation accuracy vs SVM(rbf kernel) gamma')\nplt.ylabel('Accuracy')\nplt.xlabel('Gamma')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:30:50.670171Z","iopub.execute_input":"2022-01-28T07:30:50.670414Z","iopub.status.idle":"2022-01-28T07:30:51.045149Z","shell.execute_reply.started":"2022-01-28T07:30:50.670363Z","shell.execute_reply":"2022-01-28T07:30:51.044304Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = LogisticRegression(C=0.006\n                             ,random_state=0)\n    rbf.fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_test[s])\n    accuracy = accuracy_score(y_test, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:32:19.926009Z","iopub.execute_input":"2022-01-28T07:32:19.926596Z","iopub.status.idle":"2022-01-28T07:32:20.317737Z","shell.execute_reply.started":"2022-01-28T07:32:19.926549Z","shell.execute_reply":"2022-01-28T07:32:20.316871Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"s=['status', '1']\nrbf = LogisticRegression(C=0.005,random_state=0)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:32:24.660451Z","iopub.execute_input":"2022-01-28T07:32:24.661053Z","iopub.status.idle":"2022-01-28T07:32:24.684200Z","shell.execute_reply.started":"2022-01-28T07:32:24.661013Z","shell.execute_reply":"2022-01-28T07:32:24.683411Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = tree.DecisionTreeClassifier()\n    clf = clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)\n#tree.plot_tree(clf)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:32:26.452953Z","iopub.execute_input":"2022-01-28T07:32:26.453253Z","iopub.status.idle":"2022-01-28T07:32:26.672736Z","shell.execute_reply.started":"2022-01-28T07:32:26.453201Z","shell.execute_reply":"2022-01-28T07:32:26.671678Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1']\nrbf = tree.DecisionTreeClassifier()\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:32:29.967198Z","iopub.execute_input":"2022-01-28T07:32:29.967503Z","iopub.status.idle":"2022-01-28T07:32:29.984893Z","shell.execute_reply.started":"2022-01-28T07:32:29.967468Z","shell.execute_reply":"2022-01-28T07:32:29.984039Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nresult=[]\nmax_depth=range(1,101)\nn_estimators=range(40,141)\nmax_features=range(1,6)\n#for depth in max_depth:\nfor n in n_estimators:\n#for features in max_features:\n        clf = RandomForestClassifier(criterion='entropy',max_depth=22,n_estimators=n,max_features=2)\n        clf = clf.fit(X_train, y_train)\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(n_estimators, result)\nplt.title('validation accuracy vs maximum number RandomForest terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum number')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:32:31.431341Z","iopub.execute_input":"2022-01-28T07:32:31.432295Z","iopub.status.idle":"2022-01-28T07:33:04.030909Z","shell.execute_reply.started":"2022-01-28T07:32:31.432219Z","shell.execute_reply":"2022-01-28T07:33:04.030097Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nresult=[]\nmax_depth=range(20,30)\nn_estimators=range(20,30)\nmax_features=range(1,6)\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = RandomForestClassifier(criterion='entropy',max_depth=22,n_estimators=40,max_features=min(2,len(s)))\n    clf = clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:33:04.032503Z","iopub.execute_input":"2022-01-28T07:33:04.033384Z","iopub.status.idle":"2022-01-28T07:33:07.732008Z","shell.execute_reply.started":"2022-01-28T07:33:04.033345Z","shell.execute_reply":"2022-01-28T07:33:07.731059Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1']\nrbf = RandomForestClassifier(criterion='entropy',max_depth=22,n_estimators=40,max_features=min(2,len(s)))\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:33:07.732998Z","iopub.execute_input":"2022-01-28T07:33:07.733203Z","iopub.status.idle":"2022-01-28T07:33:07.883162Z","shell.execute_reply.started":"2022-01-28T07:33:07.733179Z","shell.execute_reply":"2022-01-28T07:33:07.882391Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nresult=[]\nmax_feature=range(1,6)\nn_estimators=range(1,51)\nfor f in max_feature:\n    for n in n_estimators:\n        #X=df_last1[s]\n        #y=df_last1[\"play cat\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n        clf = BaggingClassifier(KNeighborsClassifier(),max_samples=1.0, max_features=f,n_estimators=n)\n        clf.fit(X_train, y_train)\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        result.append((f,n,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:33:07.884825Z","iopub.execute_input":"2022-01-28T07:33:07.885116Z","iopub.status.idle":"2022-01-28T07:33:48.266350Z","shell.execute_reply.started":"2022-01-28T07:33:07.885085Z","shell.execute_reply":"2022-01-28T07:33:48.265594Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nresult=[]\nfor s in end_list:\n        #X=df_last1[s]\n        #y=df_last1[\"play cat\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = BaggingClassifier(KNeighborsClassifier(),max_samples=1.0, max_features=min(2,len(s)),n_estimators=27)\n    clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:33:48.267531Z","iopub.execute_input":"2022-01-28T07:33:48.267831Z","iopub.status.idle":"2022-01-28T07:33:53.041311Z","shell.execute_reply.started":"2022-01-28T07:33:48.267802Z","shell.execute_reply":"2022-01-28T07:33:53.040318Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', 'topic', '2']\nrbf =BaggingClassifier(KNeighborsClassifier(),max_samples=1.0, max_features=min(2,len(s)),n_estimators=27)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:33:53.042455Z","iopub.execute_input":"2022-01-28T07:33:53.042667Z","iopub.status.idle":"2022-01-28T07:33:53.186825Z","shell.execute_reply.started":"2022-01-28T07:33:53.042641Z","shell.execute_reply":"2022-01-28T07:33:53.185998Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import AdaBoostClassifier\nn_estimators =range(110,211)\nresult=[]\nfor n in n_estimators:\n    #for n in n_estimators:\n        #X=df_last1[s]\n        #y=df_last1[\"play cat\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = AdaBoostClassifier(n_estimators=n)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(range(110,211), result)\nplt.title('validation accuracy vs maximum number Adaboosting terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum number')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:33:53.188204Z","iopub.execute_input":"2022-01-28T07:33:53.189018Z","iopub.status.idle":"2022-01-28T07:34:32.148401Z","shell.execute_reply.started":"2022-01-28T07:33:53.188975Z","shell.execute_reply":"2022-01-28T07:34:32.147638Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n#from sklearn.datasets import load_iris\nfrom sklearn.ensemble import AdaBoostClassifier\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = AdaBoostClassifier(n_estimators=155)\n    clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:34:32.149780Z","iopub.execute_input":"2022-01-28T07:34:32.150178Z","iopub.status.idle":"2022-01-28T07:34:42.785092Z","shell.execute_reply.started":"2022-01-28T07:34:32.150149Z","shell.execute_reply":"2022-01-28T07:34:42.784286Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', 'topic', '2']\nrbf = AdaBoostClassifier(n_estimators=155)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:34:42.786494Z","iopub.execute_input":"2022-01-28T07:34:42.786938Z","iopub.status.idle":"2022-01-28T07:34:43.152815Z","shell.execute_reply.started":"2022-01-28T07:34:42.786908Z","shell.execute_reply":"2022-01-28T07:34:43.151921Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = GradientBoostingClassifier(n_estimators=22, learning_rate=1.0,max_depth=3, random_state=0)\n    clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:34:43.155011Z","iopub.execute_input":"2022-01-28T07:34:43.155245Z","iopub.status.idle":"2022-01-28T07:34:47.016700Z","shell.execute_reply.started":"2022-01-28T07:34:43.155207Z","shell.execute_reply":"2022-01-28T07:34:47.015918Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmax_depth=[1,2,3,4,5,6,7]\nn_estimators=range(1,101)\nresult=[]\nfor n in n_estimators:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = GradientBoostingClassifier(n_estimators=n, learning_rate=1.0,max_depth=3, random_state=0)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    result.append(accuracy)\n#result.sort(key= lambda x:x[1],reverse=True)\n#for outcome in result:\n    #print(outcome)\nimport matplotlib.pyplot as plt\nplt.plot(range(1,101), result)\nplt.title('validation accuracy vs maximum number Gradientboosting terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum number')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:34:47.017674Z","iopub.execute_input":"2022-01-28T07:34:47.018368Z","iopub.status.idle":"2022-01-28T07:35:23.948875Z","shell.execute_reply.started":"2022-01-28T07:34:47.018337Z","shell.execute_reply":"2022-01-28T07:35:23.947813Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmax_depth=range(1,11)\nn_estimators=range(1,101)\nresult=[]\nfor d in max_depth:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = GradientBoostingClassifier(n_estimators=22, learning_rate=1.0,max_depth=d, random_state=0)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    result.append(accuracy)\n#result.sort(key= lambda x:x[1],reverse=True)\n#for outcome in result:\n    #print(outcome)\nimport matplotlib.pyplot as plt\nplt.plot(max_depth, result)\nplt.title('validation accuracy vs maximum depth Gradientboosting terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum depth')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:35:23.950456Z","iopub.execute_input":"2022-01-28T07:35:23.950959Z","iopub.status.idle":"2022-01-28T07:35:27.918188Z","shell.execute_reply.started":"2022-01-28T07:35:23.950915Z","shell.execute_reply":"2022-01-28T07:35:27.917137Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', 'topic', '2']\nrbf = GradientBoostingClassifier(n_estimators=22, learning_rate=1.0,max_depth=3, random_state=0)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-28T07:35:27.919878Z","iopub.execute_input":"2022-01-28T07:35:27.921571Z","iopub.status.idle":"2022-01-28T07:35:28.085756Z","shell.execute_reply.started":"2022-01-28T07:35:27.921527Z","shell.execute_reply":"2022-01-28T07:35:28.084912Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}