{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n#df = pd.read_csv('/kaggle/input/tencentforuse/edit')\nnew_df=pd.read_csv('/kaggle/input/newclustering/newclasstering.csv')\nnew_df","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:24.687265Z","iopub.execute_input":"2021-12-11T14:48:24.687635Z","iopub.status.idle":"2021-12-11T14:48:24.751601Z","shell.execute_reply.started":"2021-12-11T14:48:24.687596Z","shell.execute_reply":"2021-12-11T14:48:24.750905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalized_df=(df_new-df_new.mean())/df_new.std()\n#new_df=new_df.fillna(new_df.mean())\nnew_df[['status']]=new_df[['status']].fillna(round(new_df.mean()))\nnew_df=new_df.fillna(0)\nnormalized=pd.DataFrame()\nnormalized['status']=(new_df['status']-new_df['status'].mean())/new_df['status'].std()\nnormalized['play number']=(new_df['play number']-new_df['play number'].mean())/new_df['play number'].std()\nnormalized['score']=(new_df['score']-new_df['score'].mean())/new_df['score'].std()\n#normalized['year']=new_df['year']-2015\nnormalized['year']=(new_df['year']-new_df['year'].mean())/new_df['year'].std()\n#normalized['topic']=new_df['topic']-7\nnormalized['topic']=(new_df['topic']-new_df['topic'].mean())/new_df['topic'].std()\nnormalized['1']=(new_df['1']-new_df['1'].mean())/new_df['1'].std()\nnormalized['2']=(new_df['2']-new_df['2'].mean())/new_df['2'].std()\nnormalized['sum']=(new_df['sum']-new_df['sum'].mean())/new_df['sum'].std()\nnormalized['play cat']=new_df['play cat']\ndf_last1=normalized\ndf_last1\n#new_df","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:24.753293Z","iopub.execute_input":"2021-12-11T14:48:24.75376Z","iopub.status.idle":"2021-12-11T14:48:24.793444Z","shell.execute_reply.started":"2021-12-11T14:48:24.753725Z","shell.execute_reply":"2021-12-11T14:48:24.792728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from lightgbm import LGBMRegressor, LGBMClassifier\nfrom sklearn.model_selection import train_test_split\n#test=df_last1[['status','score','year', 'topic','1','2','sum']]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:24.794538Z","iopub.execute_input":"2021-12-11T14:48:24.794872Z","iopub.status.idle":"2021-12-11T14:48:25.657883Z","shell.execute_reply.started":"2021-12-11T14:48:24.794821Z","shell.execute_reply":"2021-12-11T14:48:25.657182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##https://blog.csdn.net/weixin_42029733/article/details/89922575\nfrom itertools import combinations\ndef combine(temp_list,n):\n    temp_list2 = []\n    for c in combinations(temp_list, n):\n        temp_list2.append(list(c))\n    return temp_list2\ntest=['status','year', 'topic','1','2']\nend_list=[]\nfor i in range(len(test)):\n    end_list.extend(list(combine(test,i)))\ndel end_list[0]\nend_list.append(test)\n#end_list","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:25.660018Z","iopub.execute_input":"2021-12-11T14:48:25.660264Z","iopub.status.idle":"2021-12-11T14:48:25.666122Z","shell.execute_reply.started":"2021-12-11T14:48:25.660231Z","shell.execute_reply":"2021-12-11T14:48:25.665201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm, datasets\nimport sklearn.model_selection as model_selection\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:25.667231Z","iopub.execute_input":"2021-12-11T14:48:25.669005Z","iopub.status.idle":"2021-12-11T14:48:25.797871Z","shell.execute_reply.started":"2021-12-11T14:48:25.668965Z","shell.execute_reply":"2021-12-11T14:48:25.797183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:25.799189Z","iopub.execute_input":"2021-12-11T14:48:25.799441Z","iopub.status.idle":"2021-12-11T14:48:25.803746Z","shell.execute_reply.started":"2021-12-11T14:48:25.799407Z","shell.execute_reply":"2021-12-11T14:48:25.80296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ratio = 0.75\nvalidation_ratio = 0.15\ntest_ratio = 0.10\n\n# train is now 75% of the entire data set\n# the _junk suffix means that we drop that variable completely\ndataX=df_last1[test]\ndataY=df_last1[\"play cat\"]\nX_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n# test is now 10% of the initial data set\n# validation is now 15% of the initial data set\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:25.805036Z","iopub.execute_input":"2021-12-11T14:48:25.805275Z","iopub.status.idle":"2021-12-11T14:48:25.824149Z","shell.execute_reply.started":"2021-12-11T14:48:25.805241Z","shell.execute_reply":"2021-12-11T14:48:25.823349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#gamma=[0.03,0.1,0.3,1]\n#C=[0.1,1,10,100]\nC=[0.1*i for i in range(10,51)]\ngamma=[i for i in range(4,30)]\nrecord=[]\nfor g in gamma:\n#for c in C:\n    rbf = svm.SVC(kernel='rbf', gamma=g, C=2.3).fit(X_train, y_train)\n    rbf_pred = rbf.predict(X_val)\n    accuracy = accuracy_score(y_val, rbf_pred)\n    record.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(gamma, record)\nplt.title('validation accuracy vs SVM(rbf kernel) gamma')\nplt.ylabel('Accuracy')\nplt.xlabel('Gamma')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:25.826441Z","iopub.execute_input":"2021-12-11T14:48:25.827027Z","iopub.status.idle":"2021-12-11T14:48:31.393524Z","shell.execute_reply.started":"2021-12-11T14:48:25.826989Z","shell.execute_reply":"2021-12-11T14:48:31.392898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=[]\ngamma=[0.5,1.0,1.5,2.0]\nC=[1.0,1.2,1.4,1.6,1.8,2.0]\nfor s in end_list:\n    #X=X_train[s]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n    rbf = svm.SVC(kernel='rbf', gamma=12, C=2.3).fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:59:22.994176Z","iopub.execute_input":"2021-12-11T14:59:22.994425Z","iopub.status.idle":"2021-12-11T14:59:27.717572Z","shell.execute_reply.started":"2021-12-11T14:59:22.994398Z","shell.execute_reply":"2021-12-11T14:59:27.71683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1', '2']\nrbf = svm.SVC(kernel='rbf', gamma=12, C=2.3).fit(X_train[s], y_train)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:59:46.703821Z","iopub.execute_input":"2021-12-11T14:59:46.704358Z","iopub.status.idle":"2021-12-11T14:59:47.018127Z","shell.execute_reply.started":"2021-12-11T14:59:46.704322Z","shell.execute_reply":"2021-12-11T14:59:47.017327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02\nrbf = svm.SVC(kernel='rbf', gamma=2, C=1.8).fit(X_train, y_train)\npoly = svm.SVC(kernel='poly', degree=3, C=10).fit(X_train, y_train)\nsig = svm.SVC(kernel='sigmoid', C=10).fit(X_train, y_train)\nlinear = svm.SVC(kernel='linear', C=10).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:36.343276Z","iopub.execute_input":"2021-12-11T14:48:36.343672Z","iopub.status.idle":"2021-12-11T14:48:37.24301Z","shell.execute_reply.started":"2021-12-11T14:48:36.343636Z","shell.execute_reply":"2021-12-11T14:48:37.242266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_pred = poly.predict(X_test)\nrbf_pred = rbf.predict(X_test)\nsig_pred=sig.predict(X_test)\nlinear_pred=linear.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:37.244452Z","iopub.execute_input":"2021-12-11T14:48:37.244993Z","iopub.status.idle":"2021-12-11T14:48:37.293094Z","shell.execute_reply.started":"2021-12-11T14:48:37.244954Z","shell.execute_reply":"2021-12-11T14:48:37.292468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_accuracy = accuracy_score(y_test, poly_pred)\npoly_f1 = f1_score(y_test, poly_pred, average='weighted')\nprint('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\nprint('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n\nrbf_accuracy = accuracy_score(y_test, rbf_pred)\nrbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\nprint('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\nprint('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))\n\nsig_accuracy = accuracy_score(y_test, sig_pred)\nsig_f1 = f1_score(y_test, sig_pred, average='weighted')\nprint('Accuracy (Sig Kernel): ', \"%.2f\" % (sig_accuracy*100))\nprint('F1 (Sig Kernel): ', \"%.2f\" % (sig_f1*100))\n\nlinear_accuracy = accuracy_score(y_test, linear_pred)\nlinear_f1 = f1_score(y_test, linear_pred, average='weighted')\nprint('Accuracy (Linear Kernel): ', \"%.2f\" % (linear_accuracy*100))\nprint('F1 (Linear Kernel): ', \"%.2f\" % (linear_f1*100))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:37.29411Z","iopub.execute_input":"2021-12-11T14:48:37.294353Z","iopub.status.idle":"2021-12-11T14:48:37.314187Z","shell.execute_reply.started":"2021-12-11T14:48:37.294319Z","shell.execute_reply":"2021-12-11T14:48:37.313504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt \naccu=[]\nn_neighbors=range(10,60)\nmatric=['euclidean','manhattan','minkowski','hamming']\n#for n in n_neighbors:\nfor m in ['uniform','distance']:\n    neigh = KNeighborsClassifier(weights=m,n_neighbors=24)\n    neigh.fit(X_train, y_train)\n    neigh_pred=neigh.predict(X_val)\n    neigh_accuracy = accuracy_score(y_val, neigh_pred)\n    print(m,neigh_accuracy)\n#import matplotlib.pyplot as plt\n#plt.plot(n_neighbors, accu)\n#plt.title('validation accuracy vs Number of neighbors(K) in KNN')\n#plt.ylabel('Accuracy')\n#plt.xlabel('Number of neighbors')\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:37.315466Z","iopub.execute_input":"2021-12-11T14:48:37.316073Z","iopub.status.idle":"2021-12-11T14:48:37.418467Z","shell.execute_reply.started":"2021-12-11T14:48:37.316037Z","shell.execute_reply":"2021-12-11T14:48:37.417525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = KNeighborsClassifier(weights='distance',n_neighbors=24)\n    rbf.fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:00:46.036125Z","iopub.execute_input":"2021-12-11T15:00:46.036373Z","iopub.status.idle":"2021-12-11T15:00:46.336309Z","shell.execute_reply.started":"2021-12-11T15:00:46.036345Z","shell.execute_reply":"2021-12-11T15:00:46.335534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1']\nrbf = KNeighborsClassifier(weights='distance',n_neighbors=24)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:00:58.322575Z","iopub.execute_input":"2021-12-11T15:00:58.322834Z","iopub.status.idle":"2021-12-11T15:00:58.345455Z","shell.execute_reply.started":"2021-12-11T15:00:58.322804Z","shell.execute_reply":"2021-12-11T15:00:58.344767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\n#reg =RidgeClassifier()\n#reg = linear_model.Lasso(alpha=0.9)\n#reg.fit(X_train, y_train)\n#reg_pred=reg.predict(X_test)\n#print(reg_pred)\n#reg_accuracy = accuracy_score(y_test, reg_pred)\n#reg_accuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:37.728953Z","iopub.execute_input":"2021-12-11T14:48:37.729672Z","iopub.status.idle":"2021-12-11T14:48:37.733412Z","shell.execute_reply.started":"2021-12-11T14:48:37.729636Z","shell.execute_reply":"2021-12-11T14:48:37.732632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=[]\nalpha=[1,10,100,1000,10000,100000,1000000]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = RidgeClassifier(190)\n    rbf.fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_test[s])\n    accuracy = accuracy_score(y_test, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:50:20.673674Z","iopub.execute_input":"2021-12-11T14:50:20.674224Z","iopub.status.idle":"2021-12-11T14:50:20.845229Z","shell.execute_reply.started":"2021-12-11T14:50:20.674184Z","shell.execute_reply":"2021-12-11T14:50:20.844505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', '1']\nrbf = RidgeClassifier(190)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:50:57.157524Z","iopub.execute_input":"2021-12-11T14:50:57.15779Z","iopub.status.idle":"2021-12-11T14:50:57.178226Z","shell.execute_reply.started":"2021-12-11T14:50:57.157762Z","shell.execute_reply":"2021-12-11T14:50:57.177461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\nresult=[]\nalpha=[i for i in range(1,1000)]\nfor a in alpha:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = RidgeClassifier(alpha=a)\n    rbf.fit(X_train, y_train)\n    rbf_pred = rbf.predict(X_val)\n    accuracy = accuracy_score(y_val, rbf_pred)\n    result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(alpha, result)\nplt.title('validation accuracy vs SVM(rbf kernel) gamma')\nplt.ylabel('Accuracy')\nplt.xlabel('Gamma')\nplt.legend()\nplt.show()\n#import matplotlib.pyplot as plt\n#plt.plot(range(-5,5), result)\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:51:35.627824Z","iopub.execute_input":"2021-12-11T14:51:35.628211Z","iopub.status.idle":"2021-12-11T14:51:40.610526Z","shell.execute_reply.started":"2021-12-11T14:51:35.628166Z","shell.execute_reply":"2021-12-11T14:51:40.609798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nresult=[]\nC=[0.001*i for i in range(1,15)]\nfor c in C:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = LogisticRegression(C=c,random_state=0)\n    rbf.fit(X_train, y_train)\n    rbf_pred = rbf.predict(X_test)\n    accuracy = accuracy_score(y_test, rbf_pred)\n    result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(C, result)\nplt.title('validation accuracy vs SVM(rbf kernel) gamma')\nplt.ylabel('Accuracy')\nplt.xlabel('Gamma')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:51:40.788598Z","iopub.execute_input":"2021-12-11T14:51:40.789068Z","iopub.status.idle":"2021-12-11T14:51:41.16425Z","shell.execute_reply.started":"2021-12-11T14:51:40.789033Z","shell.execute_reply":"2021-12-11T14:51:41.163589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    rbf = LogisticRegression(C=svm\n                             ,random_state=0)\n    rbf.fit(X_train[s], y_train)\n    rbf_pred = rbf.predict(X_test[s])\n    accuracy = accuracy_score(y_test, rbf_pred)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:51:41.503974Z","iopub.execute_input":"2021-12-11T14:51:41.504612Z","iopub.status.idle":"2021-12-11T14:51:41.853882Z","shell.execute_reply.started":"2021-12-11T14:51:41.504578Z","shell.execute_reply":"2021-12-11T14:51:41.85306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', '1']\nrbf = LogisticRegression(C=0.005,random_state=0)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:53:04.323737Z","iopub.execute_input":"2021-12-11T14:53:04.32441Z","iopub.status.idle":"2021-12-11T14:53:04.349291Z","shell.execute_reply.started":"2021-12-11T14:53:04.324371Z","shell.execute_reply":"2021-12-11T14:53:04.348546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = tree.DecisionTreeClassifier()\n    clf = clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)\n#tree.plot_tree(clf)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.00415Z","iopub.status.idle":"2021-12-11T14:48:38.004934Z","shell.execute_reply.started":"2021-12-11T14:48:38.004683Z","shell.execute_reply":"2021-12-11T14:48:38.004713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1']\nrbf = tree.DecisionTreeClassifier()\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.006077Z","iopub.status.idle":"2021-12-11T14:48:38.006883Z","shell.execute_reply.started":"2021-12-11T14:48:38.006631Z","shell.execute_reply":"2021-12-11T14:48:38.006658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nresult=[]\nmax_depth=range(1,101)\nn_estimators=range(40,141)\nmax_features=range(1,6)\n#for depth in max_depth:\nfor n in n_estimators:\n#for features in max_features:\n        clf = RandomForestClassifier(criterion='entropy',max_depth=22,n_estimators=n,max_features=2)\n        clf = clf.fit(X_train, y_train)\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(n_estimators, result)\nplt.title('validation accuracy vs maximum number RandomForest terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum number')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.013282Z","iopub.status.idle":"2021-12-11T14:48:38.014121Z","shell.execute_reply.started":"2021-12-11T14:48:38.013879Z","shell.execute_reply":"2021-12-11T14:48:38.013904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nresult=[]\nmax_depth=range(20,30)\nn_estimators=range(20,30)\nmax_features=range(1,6)\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = RandomForestClassifier(criterion='entropy',max_depth=22,n_estimators=40,max_features=min(2,len(s)))\n    clf = clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.015304Z","iopub.status.idle":"2021-12-11T14:48:38.016082Z","shell.execute_reply.started":"2021-12-11T14:48:38.015819Z","shell.execute_reply":"2021-12-11T14:48:38.015865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', '1']\nrbf = RandomForestClassifier(criterion='entropy',max_depth=22,n_estimators=40,max_features=min(2,len(s)))\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.017333Z","iopub.status.idle":"2021-12-11T14:48:38.018122Z","shell.execute_reply.started":"2021-12-11T14:48:38.017895Z","shell.execute_reply":"2021-12-11T14:48:38.017919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nresult=[]\nmax_feature=range(1,6)\nn_estimators=range(1,51)\nfor f in max_feature:\n    for n in n_estimators:\n        #X=df_last1[s]\n        #y=df_last1[\"play cat\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n        clf = BaggingClassifier(KNeighborsClassifier(),max_samples=1.0, max_features=f,n_estimators=n)\n        clf.fit(X_train, y_train)\n        predictions = clf.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        result.append((f,n,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.019278Z","iopub.status.idle":"2021-12-11T14:48:38.020039Z","shell.execute_reply.started":"2021-12-11T14:48:38.019789Z","shell.execute_reply":"2021-12-11T14:48:38.019815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nresult=[]\nfor s in end_list:\n        #X=df_last1[s]\n        #y=df_last1[\"play cat\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = BaggingClassifier(KNeighborsClassifier(),max_samples=1.0, max_features=min(2,len(s)),n_estimators=27)\n    clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[-1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:54:14.080494Z","iopub.execute_input":"2021-12-11T14:54:14.080765Z","iopub.status.idle":"2021-12-11T14:54:18.522688Z","shell.execute_reply.started":"2021-12-11T14:54:14.080736Z","shell.execute_reply":"2021-12-11T14:54:18.521165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', 'topic', '2']\nrbf =BaggingClassifier(KNeighborsClassifier(),max_samples=1.0, max_features=min(2,len(s)),n_estimators=27)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:54:28.891921Z","iopub.execute_input":"2021-12-11T14:54:28.892651Z","iopub.status.idle":"2021-12-11T14:54:29.03443Z","shell.execute_reply.started":"2021-12-11T14:54:28.892595Z","shell.execute_reply":"2021-12-11T14:54:29.033646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import AdaBoostClassifier\nn_estimators =range(110,211)\nresult=[]\nfor n in n_estimators:\n    #for n in n_estimators:\n        #X=df_last1[s]\n        #y=df_last1[\"play cat\"]\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = AdaBoostClassifier(n_estimators=n)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    result.append(accuracy)\nimport matplotlib.pyplot as plt\nplt.plot(range(110,211), result)\nplt.title('validation accuracy vs maximum number Adaboosting terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum number')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.025104Z","iopub.status.idle":"2021-12-11T14:48:38.025932Z","shell.execute_reply.started":"2021-12-11T14:48:38.02568Z","shell.execute_reply":"2021-12-11T14:48:38.025709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n#from sklearn.datasets import load_iris\nfrom sklearn.ensemble import AdaBoostClassifier\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = AdaBoostClassifier(n_estimators=155)\n    clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.028188Z","iopub.status.idle":"2021-12-11T14:48:38.028929Z","shell.execute_reply.started":"2021-12-11T14:48:38.028684Z","shell.execute_reply":"2021-12-11T14:48:38.028709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', 'topic', '2']\nrbf = AdaBoostClassifier(n_estimators=155)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.030024Z","iopub.status.idle":"2021-12-11T14:48:38.030759Z","shell.execute_reply.started":"2021-12-11T14:48:38.030522Z","shell.execute_reply":"2021-12-11T14:48:38.030547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nresult=[]\nfor s in end_list:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = GradientBoostingClassifier(n_estimators=22, learning_rate=1.0,max_depth=3, random_state=0)\n    clf.fit(X_train[s], y_train)\n    predictions = clf.predict(X_val[s])\n    accuracy = accuracy_score(y_val, predictions)\n    result.append((s,accuracy))\nresult.sort(key= lambda x:x[1],reverse=True)\nfor outcome in result:\n    print(outcome)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:57:36.893395Z","iopub.execute_input":"2021-12-11T14:57:36.893662Z","iopub.status.idle":"2021-12-11T14:57:40.53631Z","shell.execute_reply.started":"2021-12-11T14:57:36.893632Z","shell.execute_reply":"2021-12-11T14:57:40.535504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmax_depth=[1,2,3,4,5,6,7]\nn_estimators=range(1,101)\nresult=[]\nfor n in n_estimators:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = GradientBoostingClassifier(n_estimators=n, learning_rate=1.0,max_depth=3, random_state=0)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    result.append(accuracy)\n#result.sort(key= lambda x:x[1],reverse=True)\n#for outcome in result:\n    #print(outcome)\nimport matplotlib.pyplot as plt\nplt.plot(range(1,101), result)\nplt.title('validation accuracy vs maximum number Gradientboosting terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum number')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.033741Z","iopub.status.idle":"2021-12-11T14:48:38.03443Z","shell.execute_reply.started":"2021-12-11T14:48:38.034202Z","shell.execute_reply":"2021-12-11T14:48:38.034225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmax_depth=range(1,11)\nn_estimators=range(1,101)\nresult=[]\nfor d in max_depth:\n    #X=df_last1[s]\n    #y=df_last1[\"play cat\"]\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = GradientBoostingClassifier(n_estimators=22, learning_rate=1.0,max_depth=d, random_state=0)\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    result.append(accuracy)\n#result.sort(key= lambda x:x[1],reverse=True)\n#for outcome in result:\n    #print(outcome)\nimport matplotlib.pyplot as plt\nplt.plot(max_depth, result)\nplt.title('validation accuracy vs maximum depth Gradientboosting terminated')\nplt.ylabel('Accuracy')\nplt.xlabel('Maximum depth')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:48:38.035549Z","iopub.status.idle":"2021-12-11T14:48:38.036313Z","shell.execute_reply.started":"2021-12-11T14:48:38.036076Z","shell.execute_reply":"2021-12-11T14:48:38.036101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=['status', 'year', 'topic', '2']\nrbf = GradientBoostingClassifier(n_estimators=22, learning_rate=1.0,max_depth=3, random_state=0)\nrbf.fit(X_train[s], y_train)\nrbf_pred = rbf.predict(X_test[s])\nfrom sklearn.metrics import confusion_matrix\nx=confusion_matrix(y_test, rbf_pred)\naccuracy = accuracy_score(y_test, rbf_pred)\nprint(x)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-11T14:58:11.86435Z","iopub.execute_input":"2021-12-11T14:58:11.864597Z","iopub.status.idle":"2021-12-11T14:58:12.007284Z","shell.execute_reply.started":"2021-12-11T14:58:11.86457Z","shell.execute_reply":"2021-12-11T14:58:12.006605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}